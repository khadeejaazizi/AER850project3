{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TKlDiEZZYlY2ludaB7UK4ke_ls7L_5zm",
      "authorship_tag": "ABX9TyM+ElSzj6KFak5inelDArlx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khadeejaazizi/AER850project3/blob/main/AER850_Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3ljeXzED_-A"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/drive/My Drive/project 3 data/motherboard_image.JPEG\"\n",
        "img_real = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "img_real = cv2.rotate(img_real, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "img = cv2.GaussianBlur(img, (47, 47), 4)\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "img_gray = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 55, 7)\n",
        "img_gray = cv2.rotate(img_gray, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "# Edge detection using Canny\n",
        "edges = cv2.Canny(img_gray, threshold1=50, threshold2=300)\n",
        "edges = cv2.dilate(edges, None, iterations=10)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Create a blank mask\n",
        "mask = np.zeros_like(img_real)\n",
        "\n",
        "# Draw the largest contour on the mask\n",
        "cv2.drawContours(image=mask, contours=[max(contours, key=cv2.contourArea)], contourIdx=-1, color=(255, 255, 255), thickness=cv2.FILLED)\n",
        "\n",
        "# Extract PCB using bitwise_and\n",
        "masked_img = cv2.bitwise_and(mask, img_real)\n",
        "\n",
        "# Display each result separately\n",
        "# Original image\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(cv2.cvtColor(img_real, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Edge detection\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Edge Detection\")\n",
        "plt.imshow(edges, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Mask image\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Mask Image\")\n",
        "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Final extracted PCB\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Extracted PCB\")\n",
        "plt.imshow(cv2.cvtColor(masked_img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "tpsblxb_LGnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths to dataset and model directory\n",
        "data_path = \"/content/drive/My Drive/project 3 data/data/data.yaml\"\n",
        "model_save_path = \"/content/drive/My Drive/project 3 data/data\"\n",
        "\n",
        "# Load YOLOv8 Nano model (pretrained)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Set training hyperparameters\n",
        "hyperparameters = {\n",
        "    'epochs': 150,      # Number of training epochs\n",
        "    'batch': 4,        # Batch size per epoch\n",
        "    'imgsz': 960,       # Image size (minimum 900 for small components)\n",
        "    'name': 'pcb_detector',  # Name of the model\n",
        "    'data': data_path,  # Path to dataset configuration file\n",
        "    'project': model_save_path  # Directory to save results\n",
        "}\n",
        "\n",
        "# Train the YOLOv8 model\n",
        "print(\"Starting training...\")\n",
        "model.train(**hyperparameters)\n",
        "\n",
        "# Notify when training is complete\n",
        "print(f\"Training complete. Model saved at: {os.path.join(model_save_path, 'pcb_detector')}.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xmraorBuJOS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Path to the trained YOLOv8 model\n",
        "model_path = \"/content/drive/My Drive/project 3 data/data/pcb_detector3/weights/best.pt\"\n",
        "\n",
        "# Load the trained YOLOv8 model\n",
        "model = YOLO(model_path, task=\"detect\")\n",
        "\n",
        "# Paths to evaluation images\n",
        "eval_image_paths = [\n",
        "    \"/content/drive/My Drive/project 3 data/data/evaluation/rasppi.jpg\",\n",
        "    \"/content/drive/My Drive/project 3 data/data/evaluation/arduno.jpg\",\n",
        "    \"/content/drive/My Drive/project 3 data/data/evaluation/ardmega.jpg\"\n",
        "]\n",
        "\n",
        "\n",
        "# Directory to save evaluation results\n",
        "output_dir = \"/content/drive/My Drive/project 3 data/data/labelz\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define a color palette for different component types\n",
        "def get_unique_color(class_id):\n",
        "    colors = [\n",
        "        (0, 255, 0),  # Green\n",
        "        (0, 0, 255),  # Red\n",
        "        (255, 255, 0),  # Cyan\n",
        "        (255, 0, 255),  # Magenta\n",
        "        (0, 255, 255),  # Yellow\n",
        "\n",
        "    ]\n",
        "    return colors[class_id % len(colors)]  # Cycle through colors if classes exceed the palette\n",
        "\n",
        "# Function to evaluate the model and save annotated results\n",
        "def evaluate_and_save_results(model, image_paths):\n",
        "    saved_image_paths = []\n",
        "    for image_path in image_paths:\n",
        "        # Load the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Normalize resolution to ensure consistency\n",
        "        target_width = 950  # Define a fixed width for all images\n",
        "        aspect_ratio = image.shape[1] / image.shape[0]\n",
        "        target_height = int(target_width / aspect_ratio)\n",
        "        image = cv2.resize(image, (target_width, target_height))\n",
        "\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(image, save=False, imgsz=928, conf=0.35)\n",
        "        boxes = results[0].boxes  # Detection boxes\n",
        "        names = results[0].names  # Class names\n",
        "\n",
        "        # Draw bounding boxes and labels manually\n",
        "        for box in boxes:\n",
        "            # Extract box coordinates, confidence, and class ID\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box corners\n",
        "            conf = box.conf[0]  # Confidence\n",
        "            class_id = int(box.cls[0])  # Class ID\n",
        "\n",
        "            # unique color for each component\n",
        "            color = get_unique_color(class_id)\n",
        "            label = f\"{names[class_id]} {conf:.2f}\"\n",
        "\n",
        "            # Define custom styling\n",
        "            thickness = 2  # Thin line\n",
        "            font = cv2.FONT_HERSHEY_COMPLEX\n",
        "            font_scale = 0.33  # Smaller font size\n",
        "            font_thickness = 1\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "            # label text\n",
        "            label_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]\n",
        "            label_x, label_y = x1, y1 - 10\n",
        "            label_y = max(label_y, 10)  # Prevent label from going off the top\n",
        "            cv2.rectangle(image, (label_x, label_y - label_size[1] - 2), (label_x + label_size[0], label_y + 2), color, -1)\n",
        "            cv2.putText(image, label, (label_x, label_y), font, font_scale, (0, 0, 0), font_thickness) #tried white and black text\n",
        "        # Save the annotated image\n",
        "        filename = os.path.basename(image_path)\n",
        "        save_path = os.path.join(output_dir, filename)\n",
        "        cv2.imwrite(save_path, image)\n",
        "        saved_image_paths.append(save_path)\n",
        "        print(f\"Saved evaluation result: {save_path}\")\n",
        "    return saved_image_paths\n",
        "\n",
        "\n",
        "# Evaluate and save results\n",
        "evaluation_results = evaluate_and_save_results(model, eval_image_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RiaIZiK95QUr",
        "outputId": "ae2b426e-b415-4d4e-a78b-a5059ce8e8f6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x928 6 Capacitors, 9 Connectors, 1 Diode, 1 Electrolytic Capacitor, 7 ICs, 1 Led, 14 Resistors, 1 Transistor, 316.5ms\n",
            "Speed: 7.4ms preprocess, 316.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 928)\n",
            "Saved evaluation result: /content/drive/My Drive/project 3 data/data/labelz/rasppi.jpg\n",
            "\n",
            "0: 640x928 1 Button, 9 Capacitors, 7 Connectors, 2 Electrolytic Capacitors, 7 ICs, 4 Leds, 15 Resistors, 299.9ms\n",
            "Speed: 7.4ms preprocess, 299.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 928)\n",
            "Saved evaluation result: /content/drive/My Drive/project 3 data/data/labelz/arduno.jpg\n",
            "\n",
            "0: 832x928 1 Button, 8 Capacitors, 8 Connectors, 2 Electrolytic Capacitors, 7 ICs, 17 Resistors, 393.5ms\n",
            "Speed: 10.0ms preprocess, 393.5ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 928)\n",
            "Saved evaluation result: /content/drive/My Drive/project 3 data/data/labelz/ardmega.jpg\n"
          ]
        }
      ]
    }
  ]
}